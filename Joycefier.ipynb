{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjC9hqdgElpi",
        "outputId": "e1e26195-f8fc-42ab-c388-19ec022518de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.64.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.4 sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install bpemb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpemb import BPEmb\n",
        "import difflib\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "DhWZLFvd7Lsh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en = BPEmb(lang=\"en\", vs = 10000)\n",
        "es = BPEmb(lang=\"es\", vs = 10000)\n",
        "fr = BPEmb(lang=\"fr\", vs = 10000)\n",
        "de = BPEmb(lang='de', vs = 10000)\n",
        "\n",
        "en_words = set([item.replace('▁','') for item in en.words])\n",
        "es_words = set([item.replace('▁','') for item in es.words])\n",
        "fr_words = set([item.replace('▁','') for item in fr.words])\n",
        "de_words = set([item.replace('▁','') for item in de.words])\n",
        "\n",
        "all_words = [en_words,es_words,fr_words, de_words]"
      ],
      "metadata": {
        "id": "kI1SHH_nF3UX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('moby.txt','r') as book:\n",
        "    full_text = book.readlines()"
      ],
      "metadata": {
        "id": "N-mkLjxSKJsn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''.join(full_text)"
      ],
      "metadata": {
        "id": "wqTpYWHMTV32"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_lang():\n",
        "  return all_words[np.random.randint(len(all_words))]\n",
        "\n",
        "\n",
        "#text = '''\n",
        "#these sentences, formed without bigger words.\n",
        "#'''\n",
        "text = ''.join([c if c.isalnum() else f' {c} ' for c in text])\n",
        "\n",
        "new_text = []"
      ],
      "metadata": {
        "id": "BDBNyugv_qXp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qHTWPMHQWcdW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = ''\n",
        "for word in tqdm(text.split(' ')):\n",
        "    new_word = ''\n",
        "    try:\n",
        "        if len(word)<=4:\n",
        "            if word.isalnum():\n",
        "                if np.random.rand()>0.8:\n",
        "                    new_word = difflib.get_close_matches(word,rand_lang(),n=5)[-1]\n",
        "\n",
        "            else:\n",
        "                new_word = word\n",
        "\n",
        "        elif len(word)>4:\n",
        "            chunks = [word[:len(word)//2], word[len(word)//2:]]\n",
        "            joyce_chunks = chunks[:]\n",
        "\n",
        "            if np.random.rand()>0.5:\n",
        "                #Change first half of word by word that ends with that half\n",
        "                candidates = [item for item in rand_lang() if item.endswith(joyce_chunks[0]) and item!=joyce_chunks[0]]\n",
        "                if candidates:\n",
        "                  joyce_chunks[0] = candidates[0]\n",
        "\n",
        "            elif np.random.rand()>0.4:\n",
        "                #Change second half of word by similar\n",
        "                rand_language = all_words[np.random.randint(len(all_words))]\n",
        "                joyce_chunks[1] = difflib.get_close_matches(joyce_chunks[1],rand_lang(),n=5)[-1]\n",
        "\n",
        "            new_word = ''.join(joyce_chunks)\n",
        "            if np.random.rand()>0.8:\n",
        "                new_word = difflib.get_close_matches(word,rand_lang(),n=5)[-1]\n",
        "            #new_text.append(new_word)\n",
        "        \n",
        "        elif len(word)>9 and np.random.rand()>0.85:\n",
        "            chunks = [word[:len(word)//3], word[len(word)//3:2*len(word)//3], word[2*len(word)//3:]]\n",
        "            joyce_chunks = chunks[:]\n",
        "\n",
        "            if np.random.rand()>0.5:\n",
        "                #Change first third of word by word that ends with that half\n",
        "                candidates = [item for item in rand_lang() if item.endswith(joyce_chunks[0]) and item!=joyce_chunks[0]]\n",
        "                if candidates:\n",
        "                  joyce_chunks[0] = candidates[0]\n",
        "\n",
        "            elif np.random.rand()>0.4:\n",
        "                #Change second or third part of word by similar\n",
        "                rand_language = all_words[np.random.randint(len(all_words))]\n",
        "                part = np.random.choice([1,2])\n",
        "                joyce_chunks[part] = difflib.get_close_matches(joyce_chunks[part],rand_lang(),n=5)[-1]\n",
        "\n",
        "            new_word = ''.join(joyce_chunks)\n",
        "\n",
        "            if np.random.rand()>0.9:\n",
        "                new_word = difflib.get_close_matches(word,rand_lang(),n=5)[-1]\n",
        "\n",
        "        if new_word!='':\n",
        "          new_text.append(new_word)\n",
        "    except:\n",
        "      new_text.append(word)\n"
      ],
      "metadata": {
        "id": "-76rVkcn_ncQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb44085-3a19-4e19-cfcf-9e841669f1cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 701263/701263 [34:33<00:00, 338.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_text = ''\n",
        "for c in new_text:\n",
        "  if c.isalnum():\n",
        "    final_text+=f' {c}'\n",
        "  else:\n",
        "    final_text+=f'{c} '"
      ],
      "metadata": {
        "id": "IXqBiKAeHddQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('moby_joyced.txt','w') as newfile:\n",
        "    newfile.write(final_text)"
      ],
      "metadata": {
        "id": "GRG7fII7egqN"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}